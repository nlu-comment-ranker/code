{
 "metadata": {
  "name": "",
  "signature": "sha256:2a8a552b6721769bbfb4a956b9f4474e57356c574f668d4579e8fb19bbea6ac4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from numpy import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_hdf(\"../../tmp/xdTEST.featurescores.h5\", 'data')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>fold_0</th>\n",
        "      <th>fold_1</th>\n",
        "      <th>fold_2</th>\n",
        "      <th>fold_3</th>\n",
        "      <th>fold_4</th>\n",
        "      <th>fold_5</th>\n",
        "      <th>fold_6</th>\n",
        "      <th>fold_7</th>\n",
        "      <th>fold_8</th>\n",
        "      <th>fold_9</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>SMOG</th>\n",
        "      <td> 0.004465</td>\n",
        "      <td> 0.005044</td>\n",
        "      <td> 0.004164</td>\n",
        "      <td> 0.004858</td>\n",
        "      <td> 0.004108</td>\n",
        "      <td> 0.003954</td>\n",
        "      <td> 0.003512</td>\n",
        "      <td> 0.004010</td>\n",
        "      <td> 0.004077</td>\n",
        "      <td> 0.004478</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>entropy</th>\n",
        "      <td> 0.011568</td>\n",
        "      <td> 0.009974</td>\n",
        "      <td> 0.009588</td>\n",
        "      <td> 0.012063</td>\n",
        "      <td> 0.009575</td>\n",
        "      <td> 0.010757</td>\n",
        "      <td> 0.010960</td>\n",
        "      <td> 0.012034</td>\n",
        "      <td> 0.010526</td>\n",
        "      <td> 0.009918</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>has_verified_email</th>\n",
        "      <td> 0.000121</td>\n",
        "      <td> 0.000072</td>\n",
        "      <td> 0.000463</td>\n",
        "      <td> 0.000144</td>\n",
        "      <td> 0.000192</td>\n",
        "      <td> 0.000406</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000057</td>\n",
        "      <td> 0.000335</td>\n",
        "      <td> 0.000125</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>informativeness_global</th>\n",
        "      <td> 0.011261</td>\n",
        "      <td> 0.007080</td>\n",
        "      <td> 0.006729</td>\n",
        "      <td> 0.006269</td>\n",
        "      <td> 0.004567</td>\n",
        "      <td> 0.005706</td>\n",
        "      <td> 0.006443</td>\n",
        "      <td> 0.008882</td>\n",
        "      <td> 0.006331</td>\n",
        "      <td> 0.011174</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>informativeness_thread</th>\n",
        "      <td> 0.020578</td>\n",
        "      <td> 0.034617</td>\n",
        "      <td> 0.046020</td>\n",
        "      <td> 0.043567</td>\n",
        "      <td> 0.040248</td>\n",
        "      <td> 0.036901</td>\n",
        "      <td> 0.040734</td>\n",
        "      <td> 0.035000</td>\n",
        "      <td> 0.034391</td>\n",
        "      <td> 0.037002</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "                          fold_0    fold_1    fold_2    fold_3    fold_4  \\\n",
        "SMOG                    0.004465  0.005044  0.004164  0.004858  0.004108   \n",
        "entropy                 0.011568  0.009974  0.009588  0.012063  0.009575   \n",
        "has_verified_email      0.000121  0.000072  0.000463  0.000144  0.000192   \n",
        "informativeness_global  0.011261  0.007080  0.006729  0.006269  0.004567   \n",
        "informativeness_thread  0.020578  0.034617  0.046020  0.043567  0.040248   \n",
        "\n",
        "                          fold_5    fold_6    fold_7    fold_8    fold_9  \n",
        "SMOG                    0.003954  0.003512  0.004010  0.004077  0.004478  \n",
        "entropy                 0.010757  0.010960  0.012034  0.010526  0.009918  \n",
        "has_verified_email      0.000406  0.000000  0.000057  0.000335  0.000125  \n",
        "informativeness_global  0.005706  0.006443  0.008882  0.006331  0.011174  \n",
        "informativeness_thread  0.036901  0.040734  0.035000  0.034391  0.037002  "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mus = df.mean(axis=1)   # for each feature\n",
      "sigmas = df.std(axis=1) # for each feature\n",
      "maxlen = max(map(len, df.index))\n",
      "for f,mu,s in zip(df.index, mus, sigmas):\n",
      "    print \"%s : %.05f +/- %.05f\" % (f.ljust(maxlen), mu, s / sqrt(df.shape[1] - 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SMOG                              : 0.00427 +/- 0.00015\n",
        "entropy                           : 0.01070 +/- 0.00032\n",
        "has_verified_email                : 0.00019 +/- 0.00005\n",
        "informativeness_global            : 0.00744 +/- 0.00075\n",
        "informativeness_thread            : 0.03691 +/- 0.00232\n",
        "is_gold                           : 0.00471 +/- 0.00070\n",
        "is_mod                            : 0.00030 +/- 0.00007\n",
        "n_chars                           : 0.01026 +/- 0.00073\n",
        "n_paragraphs                      : 0.00735 +/- 0.00053\n",
        "n_sentences                       : 0.01217 +/- 0.00120\n",
        "n_uppercase                       : 0.01576 +/- 0.00148\n",
        "n_words                           : 0.00645 +/- 0.00075\n",
        "parent_jaccard_overlap            : 0.00358 +/- 0.00018\n",
        "parent_term_overlap               : 0.00469 +/- 0.00034\n",
        "parent_tfidf_overlap              : 0.00459 +/- 0.00025\n",
        "pos_f_adj                         : 0.00365 +/- 0.00042\n",
        "pos_f_adv                         : 0.00225 +/- 0.00022\n",
        "pos_f_inter                       : 0.00000 +/- 0.00000\n",
        "pos_f_noun                        : 0.00286 +/- 0.00018\n",
        "pos_f_nounproper                  : 0.00363 +/- 0.00022\n",
        "pos_f_numeral                     : 0.00148 +/- 0.00014\n",
        "pos_f_particle                    : 0.00303 +/- 0.00064\n",
        "pos_f_verb                        : 0.00580 +/- 0.00033\n",
        "pos_f_wh                          : 0.00395 +/- 0.00040\n",
        "position_rank                     : 0.00899 +/- 0.00200\n",
        "timedelta                         : 0.47541 +/- 0.00871\n",
        "tok_n_emph                        : 0.00074 +/- 0.00010\n",
        "tok_n_links                       : 0.00472 +/- 0.00051\n",
        "tok_n_nums                        : 0.00261 +/- 0.00024\n",
        "tok_n_quote                       : 0.00004 +/- 0.00002\n",
        "user_global_comment_avg_neg_karma : 0.00204 +/- 0.00016\n",
        "user_global_comment_avg_net_karma : 0.00463 +/- 0.00058\n",
        "user_global_comment_avg_pos_karma : 0.00281 +/- 0.00059\n",
        "user_global_comment_count         : 0.00158 +/- 0.00035\n",
        "user_global_comment_neg_karma     : 0.00280 +/- 0.00020\n",
        "user_global_comment_net_karma     : 0.00711 +/- 0.00080\n",
        "user_global_comment_pos_karma     : 0.00506 +/- 0.00048\n",
        "user_global_sub_avg_neg_karma     : 0.00244 +/- 0.00017\n",
        "user_global_sub_avg_net_karma     : 0.00344 +/- 0.00016\n",
        "user_global_sub_avg_pos_karma     : 0.00204 +/- 0.00024\n",
        "user_global_sub_count             : 0.00366 +/- 0.00055\n",
        "user_global_sub_neg_karma         : 0.00156 +/- 0.00012\n",
        "user_global_sub_net_karma         : 0.00118 +/- 0.00019\n",
        "user_global_sub_pos_karma         : 0.00082 +/- 0.00007\n",
        "user_local_comment_avg_neg_karma  : 0.00926 +/- 0.00096\n",
        "user_local_comment_avg_net_karma  : 0.22588 +/- 0.01019\n",
        "user_local_comment_avg_pos_karma  : 0.01834 +/- 0.00125\n",
        "user_local_comment_count          : 0.00776 +/- 0.00045\n",
        "user_local_comment_neg_karma      : 0.00383 +/- 0.00071\n",
        "user_local_comment_net_karma      : 0.03014 +/- 0.00625\n",
        "user_local_comment_pos_karma      : 0.00693 +/- 0.00172\n",
        "user_local_sub_avg_neg_karma      : 0.00128 +/- 0.00007\n",
        "user_local_sub_avg_net_karma      : 0.00129 +/- 0.00014\n",
        "user_local_sub_avg_pos_karma      : 0.00124 +/- 0.00006\n",
        "user_local_sub_count              : 0.00153 +/- 0.00017\n",
        "user_local_sub_neg_karma          : 0.00075 +/- 0.00012\n",
        "user_local_sub_net_karma          : 0.00114 +/- 0.00017\n",
        "user_local_sub_pos_karma          : 0.00096 +/- 0.00012\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}